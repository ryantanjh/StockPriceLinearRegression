# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vf5rqAs5_vU9jnjai7wWM3xGnEM0JXRy
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
df = pd.read_csv('/content/drive/MyDrive/VI.csv')

#Replace NM with nan and remove rows
df = df.replace(to_replace="NM", value=np.nan)
df = df.dropna()

#Convert date format 
df['EndDate']= pd.to_datetime(df['End Period'])
#Separate training data and test data 
df_train = df.loc[(df['EndDate'] >= '2010-12-31') & (df['EndDate'] <= '2020-12-31')]
df_test = df.loc[(df['EndDate'] > '2020-12-31')]

#Remove symbols in data 
for r in range(5, len(df.columns)): 
  df_train[df_train.columns[r]] = df_train[df_train.columns[r]].replace('[\$,%]', '', regex=True)
  df_test[df_train.columns[r]] = df_test[df_train.columns[r]].replace('[\$,%]', '', regex=True)
print(df_train)
#creating unique id col 
df_test.insert(0, "ID", list(range(len(df_test))))
df_test_full = df_test #full version of data before we remove columns
#Remove non numerical columns so that dropna does not delete entire dataset 
df_train = df_train.drop(columns=['EndDate', 'Start Period', 'End Period', 'Ticker Code', 'Company Name' ])
df_test= df_test.drop(columns=['EndDate', 'Start Period', 'End Period', 'Ticker Code', 'Company Name' ])
#Convert string to floats and convert invalid strings to nan
df_train = df_train.apply(pd.to_numeric, errors='coerce')
df_test = df_test.apply(pd.to_numeric, errors='coerce')

#Delete rows containing invalid numericl data 
df_train = df_train.dropna()
df_test = df_test.dropna()

#View correlations between data 
# corr = df_train.corr()
# mask = np.zeros_like(corr, dtype=bool)
# mask[np.triu_indices_from(mask)] = True
# corr[mask] = np.nan
# (corr
#  .style
#  .background_gradient(cmap='coolwarm', axis=None, vmin=-1, vmax=1)
#  .highlight_null(null_color='#f1f1f1')  # Color NaNs grey
#  .set_precision(2))

#Reduce multicollinearity 
print(df_train.columns)
df_train = df_train.drop(columns=['Avg 3/6/12M Return', ' Daily Liquidity ', ' EV ', 'GP', 'EV/GP', 'P/S' ,'GPTA, -1', 'GPTA, -2',
       'GPTA, -3','GP/Capital, -1',
       'GP/Capital, -2', 'GP/Capital, -3','GP/Capital','GPM, -1',
       'GPM, -2', 'GPM, -3', 'GPM, -4', 'GPM, -5', 'GPM, -6', 'GPM, -7',
       'GPM, -8', 'SMA 50', 'SMA 100',
       'SMA 150', 'SMA 200', 'Price Volatility, 6', 'Avg GP Growth','GPTA Avg','GPTA','(GP Growth) Growth Slope', ' Avg 3 RSI ', ' Avg 6 RSI ', ' Avg 12 RSI ','ORECTA','EV/EBITDA','GP Stability S.D',])
df_test = df_test.drop(columns=['Avg 3/6/12M Return', ' Daily Liquidity ', ' EV ', 'GP', 'EV/GP', 'P/S' ,'GPTA, -1', 'GPTA, -2',
       'GPTA, -3','GP/Capital, -1',
       'GP/Capital, -2', 'GP/Capital, -3','GP/Capital','GPM, -1',
       'GPM, -2', 'GPM, -3', 'GPM, -4', 'GPM, -5', 'GPM, -6', 'GPM, -7',
       'GPM, -8', 'SMA 50', 'SMA 100',
       'SMA 150', 'SMA 200', 'Price Volatility, 6', 'Avg GP Growth','GPTA Avg','GPTA','(GP Growth) Growth Slope', ' Avg 3 RSI ', ' Avg 6 RSI ', ' Avg 12 RSI ','ORECTA','EV/EBITDA','GP Stability S.D',])

#set independent variables and outcome variables
df_train_x = df_train.values[:, 1:] 
df_train_y = df_train.values[:, 0]
df_test_x = df_test.values[:, 2:] 
df_actual_y = df_test.values[:, 1]
#Feed training data into model
reg = LinearRegression(fit_intercept=True)
reg.fit(df_train_x, df_train_y)
#Predict outcome based on testing set 
y_pred = reg.predict(df_test_x)
print("<------------------------PREDICTED DATA----------------------------------------->")
#List of all predictions from test data, along with their ID number 
res = [] 
for i in range(len(y_pred)):
  res.append((i, y_pred[i]))
#Sort according to highest returns 
res.sort(key = lambda x: x[1], reverse=True)
#top 5 predictions 
top5_pred = res[:5]
#Display data
counter = 1
for pred in top5_pred: 
  company = df_test_full.loc[df_test_full['ID'] == pred[0]]['Company Name']
  print("-------- Rank" + str(counter) + "---------")
  print(company)
  print("Returns: " + str(round(pred[1], 2))+ "%")
  counter += 1

print("<------------------------ACTUAL DATA----------------------------------------->")
#top 5 companies actual
res_actual = []
for j in range(len(df_actual_y)):
  res_actual.append((j, df_actual_y[j])) 
res_actual.sort(key = lambda x: x[1], reverse=True)
top5_actual = res_actual[:5]
counter = 1
for act in top5_actual: 
  company = df_test_full.loc[df_test_full['ID'] == act[0]]['Company Name']
  print("-------- Rank" + str(counter) + "---------")
  print(company)
  print("Returns: " + str(act[1])+ "%")
  counter += 1
print("<-------------------------R-SQUARED---------------------------------------->")
print("Rsquared : " + str(r2_score(df_actual_y, y_pred)))
